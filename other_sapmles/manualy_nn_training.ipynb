{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112fbc71-b71b-4390-9633-e39568bb3e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Structure: (2, 2, 1)\n",
      "Initial Weights: [array([[ 0.17365166,  0.14824008,  0.04162851],\n",
      "       [ 0.02975941,  0.05697061, -0.01814336]]), array([[-0.00912843, -0.10510329,  0.03960442]])]\n",
      "Iteration 0\tError 0.810089\n",
      "Iteration 5000\tError 0.809988\n",
      "Iteration 10000\tError 0.809689\n",
      "Iteration 15000\tError 0.007611\n",
      "Iteration 20000\tError 0.000349\n",
      "Iteration 25000\tError 0.000045\n",
      "Minimum Error reached at iteration: 29169\n",
      "Input: [[0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "\n",
      "Output: [[0.05186594]\n",
      " [0.05156521]\n",
      " [0.94857523]\n",
      " [0.9485747 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BackPropagationNetwork:\n",
    "    def __init__(self, layerSize):\n",
    "        self.layerCount = len(layerSize) - 1  # Number of layers (excluding input layer)\n",
    "        self.shape = layerSize  # The structure of the neural network\n",
    "        self.weights = []  # List to store weights for each layer\n",
    "        self._layerInput = []  # Input to each layer\n",
    "        self._layerOutput = []  # Output from each layer\n",
    "\n",
    "        # Initialize weights with random values using a normal distribution\n",
    "        for (l1, l2) in zip(layerSize[:-1], layerSize[1:]):\n",
    "            self.weights.append(np.random.normal(scale=0.1, size=(l2, l1 + 1)))\n",
    "\n",
    "    def sgm(self, x, Derivative=False):\n",
    "        \"\"\"Sigmoid activation function and its derivative\"\"\"\n",
    "        if not Derivative:\n",
    "            return 1 / (1 + np.exp(-x))  # Sigmoid function\n",
    "        else:\n",
    "            out = self.sgm(x)\n",
    "            return out * (1 - out)  # Derivative of sigmoid\n",
    "\n",
    "    def run(self, input):\n",
    "        \"\"\"Run the network with given input and compute outputs\"\"\"\n",
    "        inCases = input.shape[0]  # Number of input cases\n",
    "        self._layerInput = []\n",
    "        self._layerOutput = []\n",
    "\n",
    "        # Forward propagation through all layers\n",
    "        for index in range(self.layerCount):\n",
    "            if index == 0:\n",
    "                # For the first layer, include input and bias\n",
    "                layerInput = self.weights[index].dot(np.vstack([input.T, np.ones([1, inCases])]))\n",
    "            else:\n",
    "                # For subsequent layers, use previous layer's output as input\n",
    "                layerInput = self.weights[index].dot(np.vstack([self._layerOutput[-1], np.ones([1, inCases])]))\n",
    "            self._layerInput.append(layerInput)\n",
    "            self._layerOutput.append(self.sgm(layerInput))\n",
    "\n",
    "        # Return the final output (transpose to match input format)\n",
    "        return self._layerOutput[-1].T\n",
    "\n",
    "    def trainEpoch(self, Input, target, trainingRate=0.2):\n",
    "        \"\"\"Train the network for one epoch using backpropagation\"\"\"\n",
    "        delta = []  # List to store errors (deltas) for each layer\n",
    "        inCases = Input.shape[0]  # Number of input cases\n",
    "        self.run(Input)  # Perform forward propagation\n",
    "        error = 0  # Initialize total error\n",
    "\n",
    "        # Backpropagation of errors\n",
    "        for index in reversed(range(self.layerCount)):\n",
    "            if index == self.layerCount - 1:  \n",
    "                # For the output layer\n",
    "                output_delta = self._layerOutput[index] - target.T\n",
    "                error = np.sum(output_delta ** 2)  # Mean Squared Error\n",
    "                delta.append(output_delta * self.sgm(self._layerInput[index], True))\n",
    "            else:\n",
    "                # For hidden layers, propagate errors backwards\n",
    "                delta_pullback = self.weights[index + 1].T.dot(delta[-1])\n",
    "                delta.append(delta_pullback[:-1, :] * self.sgm(self._layerInput[index], True))\n",
    "\n",
    "        # Update weights using the computed deltas\n",
    "        for index in range(self.layerCount):\n",
    "            delta_index = self.layerCount - 1 - index  # Reverse the order of deltas\n",
    "            if index == 0:\n",
    "                # Input layer: include input and bias\n",
    "                layerOutput = np.vstack([Input.T, np.ones([1, inCases])])\n",
    "            else:\n",
    "                # Hidden layers: use previous layer's output and bias\n",
    "                layerOutput = np.vstack([self._layerOutput[index - 1], np.ones([1, self._layerOutput[index - 1].shape[1]])])\n",
    "\n",
    "            # Compute weight delta and update weights\n",
    "            weightDelta = np.sum(\n",
    "                layerOutput[None, :, :].transpose(2, 0, 1) * delta[delta_index][None, :, :].transpose(2, 1, 0), axis=0)\n",
    "            self.weights[index] -= trainingRate * weightDelta\n",
    "\n",
    "        return error\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a BackPropagationNetwork instance with a (2,2,1) structure\n",
    "    bpn = BackPropagationNetwork((2, 2, 1))\n",
    "    print(\"Network Structure:\", bpn.shape)\n",
    "    print(\"Initial Weights:\", bpn.weights)\n",
    "\n",
    "    # Input and target for XOR problem\n",
    "    lvInput = np.array([[0, 0], [1, 1], [0, 1], [1, 0]])\n",
    "    lvTarget = np.array([[0.05], [0.05], [0.95], [0.95]])\n",
    "\n",
    "    lnMax = 100000  # Maximum number of iterations\n",
    "    lnError = 1e-5  # Error threshold\n",
    "\n",
    "    # Training loop\n",
    "    for i in range(lnMax + 1):\n",
    "        err = bpn.trainEpoch(lvInput, lvTarget)\n",
    "        if i % 5000 == 0:\n",
    "            print(\"Iteration {0}\\tError {1:0.6f}\".format(i, err))\n",
    "        if err <= lnError:\n",
    "            print(\"Minimum Error reached at iteration: {0}\".format(i))\n",
    "            break\n",
    "\n",
    "    # Run the trained network on the input data\n",
    "    lvOutput = bpn.run(lvInput)\n",
    "    print(\"Input: {0}\\n\\nOutput: {1}\".format(lvInput, lvOutput))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c851284b-dabf-4cea-ab4f-c4aad4a4f5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
